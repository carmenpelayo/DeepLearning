{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While editing this notebook, don't change cell types as that confuses the autograder.\n",
    "\n",
    "Before you turn this notebook in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Carmen Pelayo Fern√°ndez\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Understanding Deep Learning_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DL4DS/sp2024_notebooks/blob/main/release/nbs12/12_3_Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "t9vk9Elugvmi",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43739d5477da494f099c888ae5c65108",
     "grade": false,
     "grade_id": "cell-43e8103189a2434c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Notebook 12.3: Tokenization\n",
    "\n",
    "This notebook builds set of tokens from a text string as in figure 12.8 of the book,\n",
    "employing a simplified version of the byte pair encoding algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3_WkaFO3OfLi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c0f95f6e614b09850d2f4be43d6c638",
     "grade": false,
     "grade_id": "cell-2d17781c736026c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import re, collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "tVZVuauIXmJk",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a561c709baa6bb37f940cdfe377757f4",
     "grade": false,
     "grade_id": "cell-82d351e5a84059d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "text = \"a sailor went to sea sea sea \"+\\\n",
    "                  \"to see what he could see see see \"+\\\n",
    "                  \"but all that he could see see see \"+\\\n",
    "                  \"was the bottom of the deep blue sea sea sea\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aae80729d2c228a3e1e192852ffc5fdb",
     "grade": false,
     "grade_id": "cell-d7ca0f8c19720665",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a sailor went to sea sea sea to see what he could see see see but all that he could see see see was the bottom of the deep blue sea sea sea\n",
      "139\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb42481edc49cde017f599a3eef40de4",
     "grade": false,
     "grade_id": "cell-a25511a67c163932",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fF2RBrouWV5w",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0bb96c372ebdfd54476b099b89020d49",
     "grade": false,
     "grade_id": "cell-5fe07d9db81ac9ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To begin with, the tokens are the individual letters and the </w> whitespace token. To visualize this, we represent each word in terms of these tokens with spaces between the tokens to delineate them.\n",
    "\n",
    "The tokenized text is stored in a structure that represents each word as tokens together with the count of how often that word occurs.  We'll call this the *vocabulary*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OfvXkLSARk4_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b02de447c5e73bede832a713484d9ba",
     "grade": false,
     "grade_id": "cell-826930b99f7f7276",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def initialize_vocabulary(text):\n",
    "  \"\"\"\n",
    "  Initialize the vocabulary for the BPE algorithm.\n",
    "   \n",
    "  Initialize the vocabulary from the text string we will be using to 'train' \n",
    "  the algorithm. The vocabulary is a dictionary.  The keys are the words in the\n",
    "  text and the values are the frequency of the word in the text.\n",
    "\n",
    "  Returns:\n",
    "  vocab: A dictionary where the keys are the words in the text and the values\n",
    "          are the frequency of the word in the text.\n",
    "  \"\"\"\n",
    "  vocab = collections.defaultdict(int)\n",
    "  words = text.strip().split()\n",
    "  for word in words:\n",
    "      vocab[' '.join(list(word)) + ' </w>'] += 1\n",
    "  return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "aydmNqaoOpSm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e54f98132e2cb459ca250bd31d42c522",
     "grade": false,
     "grade_id": "cell-44c64a188d21acb3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: defaultdict(<class 'int'>, {'a </w>': 1, 's a i l o r </w>': 1, 'w e n t </w>': 1, 't o </w>': 2, 's e a </w>': 6, 's e e </w>': 7, 'w h a t </w>': 1, 'h e </w>': 2, 'c o u l d </w>': 2, 'b u t </w>': 1, 'a l l </w>': 1, 't h a t </w>': 1, 'w a s </w>': 1, 't h e </w>': 2, 'b o t t o m </w>': 1, 'o f </w>': 1, 'd e e p </w>': 1, 'b l u e </w>': 1})\n",
      "Size of vocabulary: 18\n"
     ]
    }
   ],
   "source": [
    "vocab = initialize_vocabulary(text)\n",
    "print('Vocabulary: {}'.format(vocab))\n",
    "print('Size of vocabulary: {}'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fJAiCjphWsI9",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcc7b02ea3a03f59fd689c5e00d5d479",
     "grade": false,
     "grade_id": "cell-12b9c63e5cd5d749",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Find all the tokens in the current vocabulary and their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "qYi6F_K3RYsW",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5698dbb8b382c8ba3ff166dd6dec44c",
     "grade": false,
     "grade_id": "cell-e935d83eff4b3713",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_tokens_and_frequencies(vocab):\n",
    "  \"\"\"\n",
    "  Get the tokens and their frequencies from the vocabulary.\n",
    "  \n",
    "  Returns:\n",
    "  tokens: A dictionary where the keys are the tokens and the values are the\n",
    "          frequency of the token in the vocabulary.\n",
    "  \"\"\"\n",
    "  tokens = collections.defaultdict(int)\n",
    "  for word, freq in vocab.items():\n",
    "      word_tokens = word.split()\n",
    "      for token in word_tokens:\n",
    "          tokens[token] += freq\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Y4LCVGnvXIwp",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e35c662b91caaf90c0cd5a80fa73e991",
     "grade": false,
     "grade_id": "cell-cf435e2a465808ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: defaultdict(<class 'int'>, {'a': 12, '</w>': 33, 's': 15, 'i': 1, 'l': 6, 'o': 8, 'r': 1, 'w': 3, 'e': 28, 'n': 1, 't': 11, 'h': 6, 'c': 2, 'u': 4, 'd': 3, 'b': 3, 'm': 1, 'f': 1, 'p': 1})\n",
      "Number of tokens: 19\n"
     ]
    }
   ],
   "source": [
    "tokens = get_tokens_and_frequencies(vocab)\n",
    "print('Tokens: {}'.format(tokens))\n",
    "print('Number of tokens: {}'.format(len(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_-Rh1mD_Ww3b",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3bc621033585a8a4e62b50120674fe2d",
     "grade": false,
     "grade_id": "cell-6202f3a1a91e8460",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Find each pair of adjacent tokens in the vocabulary\n",
    "and count them.  We will subsequently merge the most frequently occurring pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OqJTB3UFYubH",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e63d3f81d1b07e5d7ecec6f2f3b1e95",
     "grade": false,
     "grade_id": "cell-4c6061010cf1cdd7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_pairs_and_counts(vocab):\n",
    "    \"\"\"\n",
    "    Get the pairs of symbols and their counts from the vocabulary.\n",
    "    \n",
    "    Returns:\n",
    "    pairs: A dictionary where the keys are the pairs of symbols and the values\n",
    "            are the frequency of the pair in the vocabulary.\n",
    "    \"\"\"\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "d-zm0JBcZSjS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ade8b8111973d0b9f3e31378210231f",
     "grade": false,
     "grade_id": "cell-108385ca10ed0a65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs: defaultdict(<class 'int'>, {('a', '</w>'): 7, ('s', 'a'): 1, ('a', 'i'): 1, ('i', 'l'): 1, ('l', 'o'): 1, ('o', 'r'): 1, ('r', '</w>'): 1, ('w', 'e'): 1, ('e', 'n'): 1, ('n', 't'): 1, ('t', '</w>'): 4, ('t', 'o'): 3, ('o', '</w>'): 2, ('s', 'e'): 13, ('e', 'a'): 6, ('e', 'e'): 8, ('e', '</w>'): 12, ('w', 'h'): 1, ('h', 'a'): 2, ('a', 't'): 2, ('h', 'e'): 4, ('c', 'o'): 2, ('o', 'u'): 2, ('u', 'l'): 2, ('l', 'd'): 2, ('d', '</w>'): 2, ('b', 'u'): 1, ('u', 't'): 1, ('a', 'l'): 1, ('l', 'l'): 1, ('l', '</w>'): 1, ('t', 'h'): 3, ('w', 'a'): 1, ('a', 's'): 1, ('s', '</w>'): 1, ('b', 'o'): 1, ('o', 't'): 1, ('t', 't'): 1, ('o', 'm'): 1, ('m', '</w>'): 1, ('o', 'f'): 1, ('f', '</w>'): 1, ('d', 'e'): 1, ('e', 'p'): 1, ('p', '</w>'): 1, ('b', 'l'): 1, ('l', 'u'): 1, ('u', 'e'): 1})\n",
      "Number of distinct pairs: 48\n",
      "Most frequent pair: ('s', 'e')\n"
     ]
    }
   ],
   "source": [
    "pairs = get_pairs_and_counts(vocab)\n",
    "print(f'Pairs: {pairs}')\n",
    "print(f'Number of distinct pairs: {len(pairs)}')\n",
    "\n",
    "most_frequent_pair = max(pairs, key=pairs.get)\n",
    "print(f'Most frequent pair: {most_frequent_pair}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "pcborzqIXQFS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c408ffa9faa2921a14ef7e06fae2e320",
     "grade": false,
     "grade_id": "cell-f91451269d61a640",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Merge the instances of the best pair in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xQI6NALdWQZX",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "047569ac7bf0d1a9ecaa5f3ccf88c237",
     "grade": false,
     "grade_id": "cell-68e5e94e09aaaf74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def merge_pair_in_vocabulary(pair, vocab_in):\n",
    "    \"\"\"\n",
    "    Merge a pair of symbols in the vocabulary.\n",
    "    \n",
    "    Returns:\n",
    "    vocab_out: A dictionary where the keys are the updated tokens in the \n",
    "               vocabulary and the values are the frequency of the token in the\n",
    "               vocabulary.\n",
    "    \"\"\"\n",
    "    vocab_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in vocab_in:\n",
    "        word_out = p.sub(''.join(pair), word)\n",
    "        vocab_out[word_out] = vocab_in[word]\n",
    "    return vocab_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TRYeBZI3ZULu",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfa3617c275ca33baf58be3bbab8b853",
     "grade": false,
     "grade_id": "cell-d9a169b5cd3682f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'a </w>': 1, 's a i l o r </w>': 1, 'w e n t </w>': 1, 't o </w>': 2, 'se a </w>': 6, 'se e </w>': 7, 'w h a t </w>': 1, 'h e </w>': 2, 'c o u l d </w>': 2, 'b u t </w>': 1, 'a l l </w>': 1, 't h a t </w>': 1, 'w a s </w>': 1, 't h e </w>': 2, 'b o t t o m </w>': 1, 'o f </w>': 1, 'd e e p </w>': 1, 'b l u e </w>': 1}\n",
      "Size of vocabulary: 18\n"
     ]
    }
   ],
   "source": [
    "vocab = merge_pair_in_vocabulary(most_frequent_pair, vocab)\n",
    "print(f'Vocabulary: {vocab}')\n",
    "print(f'Size of vocabulary: {len(vocab)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "bkhUx3GeXwba",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "438b967d0ebfe7807f07d6fcfec4ff91",
     "grade": false,
     "grade_id": "cell-84ec1c0d6152a4d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Update the tokens, which now include the best token 'se'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Fqj-vQWeXxQi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f17f36e53eaf7ce361a87b45774783b",
     "grade": false,
     "grade_id": "cell-df5f590521afa12a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: defaultdict(<class 'int'>, {'a': 12, '</w>': 33, 's': 2, 'i': 1, 'l': 6, 'o': 8, 'r': 1, 'w': 3, 'e': 15, 'n': 1, 't': 11, 'se': 13, 'h': 6, 'c': 2, 'u': 4, 'd': 3, 'b': 3, 'm': 1, 'f': 1, 'p': 1})\n",
      "Number of tokens: defaultdict(<class 'int'>, {'a': 12, '</w>': 33, 's': 2, 'i': 1, 'l': 6, 'o': 8, 'r': 1, 'w': 3, 'e': 15, 'n': 1, 't': 11, 'se': 13, 'h': 6, 'c': 2, 'u': 4, 'd': 3, 'b': 3, 'm': 1, 'f': 1, 'p': 1})\n"
     ]
    }
   ],
   "source": [
    "tokens = get_tokens_and_frequencies(vocab)\n",
    "print(f'Tokens: {tokens}')\n",
    "print(f'Number of tokens: {tokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "974509e0e8333aac71dd3d62c43e38b1",
     "grade": false,
     "grade_id": "cell-1bb83a53a565587d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Byte Pair Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "K_hKp2kSXXS1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e31396933a66bd100a88c3168265fbf",
     "grade": false,
     "grade_id": "cell-1c5dec87d4056965",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's write the full tokenization routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "id": "U_1SkQRGQ8f3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f524f4525bf58711269cb3c3468681b6",
     "grade": false,
     "grade_id": "cell-db0c5fc117853193",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO -- write this routine by filling in this missing parts,\n",
    "# calling the above routines\n",
    "def tokenize(text, num_merges):\n",
    "  # Initialize the vocabulary from the input text\n",
    "  # vocab = (your code here)\n",
    "  vocab = initialize_vocabulary(text)\n",
    "\n",
    "  for i in range(num_merges):\n",
    "    # Find the tokens and how often they occur in the vocabulary\n",
    "    tokens = get_tokens_and_frequencies(vocab)\n",
    "      \n",
    "    # Find the pairs of adjacent tokens and their counts\n",
    "    pairs = get_pairs_and_counts(vocab)\n",
    "\n",
    "    # Find the most frequent pair\n",
    "    most_frequent_pair = max(pairs, key=pairs.get)\n",
    "    print(f'Iter {i}: Most frequent pair: {most_frequent_pair}')\n",
    "\n",
    "    # Merge the code in the vocabulary\n",
    "    vocab = merge_pair_in_vocabulary(most_frequent_pair, vocab)\n",
    "\n",
    "  # Find the tokens and how often they occur in the vocabulary one last time\n",
    "  tokens = get_tokens_and_frequencies(vocab)\n",
    "\n",
    "  return tokens, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "w0EkHTrER_-I",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2f767fdeef0f144f512873ffb56cfda",
     "grade": false,
     "grade_id": "cell-a971fe3a2435f483",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: Most frequent pair: ('s', 'e')\n",
      "Iter 1: Most frequent pair: ('e', '</w>')\n",
      "Iter 2: Most frequent pair: ('a', '</w>')\n",
      "Iter 3: Most frequent pair: ('se', 'e</w>')\n",
      "Iter 4: Most frequent pair: ('se', 'a</w>')\n",
      "Iter 5: Most frequent pair: ('t', '</w>')\n",
      "Iter 6: Most frequent pair: ('h', 'e</w>')\n",
      "Iter 7: Most frequent pair: ('t', 'o')\n",
      "Iter 8: Most frequent pair: ('to', '</w>')\n",
      "Iter 9: Most frequent pair: ('h', 'a')\n",
      "Iter 10: Most frequent pair: ('ha', 't</w>')\n",
      "Iter 11: Most frequent pair: ('c', 'o')\n",
      "Iter 12: Most frequent pair: ('co', 'u')\n",
      "Iter 13: Most frequent pair: ('cou', 'l')\n",
      "Iter 14: Most frequent pair: ('coul', 'd')\n",
      "Iter 15: Most frequent pair: ('could', '</w>')\n",
      "Iter 16: Most frequent pair: ('t', 'he</w>')\n",
      "Iter 17: Most frequent pair: ('s', 'a')\n",
      "Iter 18: Most frequent pair: ('sa', 'i')\n",
      "Iter 19: Most frequent pair: ('sai', 'l')\n",
      "Iter 20: Most frequent pair: ('sail', 'o')\n",
      "Iter 21: Most frequent pair: ('sailo', 'r')\n"
     ]
    }
   ],
   "source": [
    "tokens, vocab = tokenize(text, num_merges=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "moqDtTzIb-NG",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fbbdc7daccb4db69eb6d96dec4f57cc0",
     "grade": false,
     "grade_id": "cell-5e6671e8aa393b17",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: defaultdict(<class 'int'>, {'a</w>': 1, 'sailor': 1, '</w>': 6, 'w': 3, 'e': 3, 'n': 1, 't</w>': 2, 'to</w>': 2, 'sea</w>': 6, 'see</w>': 7, 'hat</w>': 2, 'he</w>': 2, 'could</w>': 2, 'b': 3, 'u': 2, 'a': 2, 'l': 3, 't': 2, 's': 1, 'the</w>': 2, 'o': 2, 'to': 1, 'm': 1, 'f': 1, 'd': 1, 'p': 1, 'e</w>': 1})\n",
      "Number of tokens: 27\n",
      "Vocabulary: {'a</w>': 1, 'sailor </w>': 1, 'w e n t</w>': 1, 'to</w>': 2, 'sea</w>': 6, 'see</w>': 7, 'w hat</w>': 1, 'he</w>': 2, 'could</w>': 2, 'b u t</w>': 1, 'a l l </w>': 1, 't hat</w>': 1, 'w a s </w>': 1, 'the</w>': 2, 'b o t to m </w>': 1, 'o f </w>': 1, 'd e e p </w>': 1, 'b l u e</w>': 1}\n",
      "Size of vocabulary: 18\n"
     ]
    }
   ],
   "source": [
    "print(f'Tokens: {tokens}')\n",
    "print(f'Number of tokens: {len(tokens)}')\n",
    "print(f'Vocabulary: {vocab}')\n",
    "print(f'Size of vocabulary: {len(vocab)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf2b6cf34b617ebaa8a613e37595c35d",
     "grade": false,
     "grade_id": "cell-78b9f04495a153f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "After 22 merges of the tokenizer, you should have 27 tokens and the vocabulary consisting of 18 different tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "244d8c09b93c45e79accea439b5bdeab",
     "grade": true,
     "grade_id": "cell-3c872b92abe90a48",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test code. Do not edit.\n",
    "\n",
    "assert len(vocab) == 18\n",
    "assert len(tokens) == 27"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP0/KodWM9Dtr2x+8MdXXH1",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

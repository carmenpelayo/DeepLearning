{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While editing this notebook, don't change cell types as that confuses the autograder.\n",
    "\n",
    "Before you turn this notebook in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Carmen Pelayo Fern√°ndez\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Understanding Deep Learning_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DL4DS/sp2024_notebooks/blob/main/release/nbs10/10_3_2D_Convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "VB_crnDGASX-",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3bcfee0a52940c4ccc4b5b80a2963aa5",
     "grade": false,
     "grade_id": "cell-532fd4347f16fdbf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Notebook 10.3: 2D Convolution\n",
    "\n",
    "This notebook investigates the 2D convolution operation.  It asks you to hand code the convolution so we can be sure that we are computing the same thing as in PyTorch.  The next notebook uses the convolutional layers in PyTorch directly.\n",
    "\n",
    "Adapted from notebooks at https://github.com/udlbook/udlbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YAoWDUb_DezG",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3592323d8196d1aaefdb4cc9ce2be49",
     "grade": false,
     "grade_id": "cell-3b1aacd6ad04ca31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# Set to print in reasonable form\n",
    "np.set_printoptions(precision=3, floatmode=\"fixed\")\n",
    "torch.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eAwYWXzAElHG",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff9b5382cefaa3dbc6d7b8c88eb946b6",
     "grade": false,
     "grade_id": "cell-e119097d107f5a4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This routine performs convolution in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xsmUIN-3BlWr",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cff35582db932d87bead39e35d6dac3",
     "grade": false,
     "grade_id": "cell-c80d82bf0a0e3000",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Perform convolution in PyTorch\n",
    "def conv_pytorch(image, conv_weights, stride=1, pad =1):\n",
    "  # Convert image and kernel to tensors\n",
    "  image_tensor = torch.from_numpy(image) # (batchSize, channelsIn, imageHeightIn, imageWidthIn)\n",
    "  conv_weights_tensor = torch.from_numpy(conv_weights) # (channelsOut, channelsIn, kernelHeight, kernelWidth)\n",
    "  # Do the convolution\n",
    "  output_tensor = torch.nn.functional.conv2d(image_tensor, conv_weights_tensor, stride=stride, padding=pad)\n",
    "  # Convert back from PyTorch and return\n",
    "  return(output_tensor.numpy()) # (batchSize channelsOut imageHeightOut imageHeightIn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "A3Sm8bUWtDNO",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aba09af5aff956351a0163561cb7a5fc",
     "grade": false,
     "grade_id": "cell-8159e90ac2a26582",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First we'll start with the simplest 2D convolution.  Just one channel in and one channel out.  A single image in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "id": "EF8FWONVLo1Q",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4af8cd1a689a8dae9ff8efc25813a91",
     "grade": false,
     "grade_id": "cell-a61e75c53142f495",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Perform convolution in numpy\n",
    "def conv_numpy_1(image, weights, pad=1):\n",
    "    print(\"image shape\", image.shape)\n",
    "    print(\"weights shape\", weights.shape)\n",
    "\n",
    "    # Perform zero padding\n",
    "    if pad != 0:\n",
    "        image = np.pad(image, ((0, 0), (0, 0), (pad, pad), (pad, pad)), 'constant')\n",
    "\n",
    "    print(\"padded image shape\", image.shape)\n",
    "\n",
    "    # Get sizes of image array and kernel weights\n",
    "    batchSize,  channelsIn, imageHeightIn, imageWidthIn = image.shape\n",
    "    channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n",
    "\n",
    "    # Get size of output arrays\n",
    "    imageHeightOut = np.floor(1 + imageHeightIn - kernelHeight).astype(int)\n",
    "    imageWidthOut = np.floor(1 + imageWidthIn - kernelWidth).astype(int)\n",
    "\n",
    "    print(\"imageHeightOut\", imageHeightOut)\n",
    "    print(\"imageWidthOut\", imageWidthOut)\n",
    "\n",
    "    # Create output\n",
    "    out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype=np.float32)\n",
    "\n",
    "    # !!!!!! NOTE THERE IS A SUBTLETY HERE !!!!!!!!\n",
    "    # I have padded the image with zeros above, so it is surrouned by a \"ring\" of zeros\n",
    "    # That means that the image indexes are all off by one\n",
    "    # This actually makes your code simpler\n",
    "\n",
    "    for c_y in range(imageHeightOut):\n",
    "      for c_x in range(imageWidthOut):\n",
    "        for c_kernel_y in range(kernelHeight):\n",
    "          for c_kernel_x in range(kernelWidth):\n",
    "\n",
    "            this_pixel_value = image[0, 0, c_y + c_kernel_y, c_x + c_kernel_x]\n",
    "            this_weight = weights[0, 0, c_kernel_y, c_kernel_x]\n",
    "              \n",
    "            # Multiply these together and add to the output at this position\n",
    "            out[0, 0, c_y, c_x] += np.sum(this_pixel_value * this_weight)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "iw9KqXZTHN8v",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a30dadcd7318cece04be554b534fba67",
     "grade": false,
     "grade_id": "cell-eebbeff309bf0c87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Results\n",
      "[[[[-0.929 -2.760  0.716  0.114  0.560 -0.387]\n",
      "   [-1.515  0.283  1.008  0.466 -1.094  2.004]\n",
      "   [-1.634  3.555 -2.154 -0.892 -1.856  2.299]\n",
      "   [ 0.565 -0.947 -0.629  2.996 -1.811 -0.533]]]]\n",
      "Your results\n",
      "image shape (1, 1, 4, 6)\n",
      "weights shape (1, 1, 3, 3)\n",
      "padded image shape (1, 1, 6, 8)\n",
      "imageHeightOut 4\n",
      "imageWidthOut 6\n",
      "[[[[-0.929 -2.760  0.716  0.114  0.560 -0.387]\n",
      "   [-1.515  0.283  1.008  0.466 -1.094  2.004]\n",
      "   [-1.634  3.555 -2.154 -0.892 -1.856  2.299]\n",
      "   [ 0.565 -0.947 -0.629  2.996 -1.811 -0.533]]]]\n"
     ]
    }
   ],
   "source": [
    "# Set random seed so we always get same answer\n",
    "np.random.seed(1)\n",
    "n_batch = 1\n",
    "image_height = 4\n",
    "image_width = 6\n",
    "channels_in = 1\n",
    "kernel_size = 3\n",
    "channels_out = 1\n",
    "\n",
    "# Create random input image\n",
    "input_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))\n",
    "\n",
    "# Create random convolution kernel weights\n",
    "conv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))\n",
    "\n",
    "# Perform convolution using PyTorch\n",
    "conv_results_pytorch = conv_pytorch(input_image, conv_weights, stride=1, pad=1)\n",
    "print(\"PyTorch Results\")\n",
    "print(conv_results_pytorch)\n",
    "\n",
    "# Perform convolution in numpy\n",
    "print(\"Your results\")\n",
    "conv_results_numpy = conv_numpy_1(input_image, conv_weights)\n",
    "print(conv_results_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4e47801dc624cd6bdd9700d5198b57f",
     "grade": true,
     "grade_id": "cell-089d6608a2969310",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(conv_results_pytorch, conv_results_numpy), \"Results do not match\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "IYj_lxeGzaHX",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64a71ae856dff2cd1910f67e7bd10a17",
     "grade": false,
     "grade_id": "cell-8c35ad1f0acc2347",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's now add in the possibility of using different strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "id": "GiujmLhqHN1F",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "545e3201820ee9502cd5f80ed5f6356a",
     "grade": false,
     "grade_id": "cell-73186510ec4bdef8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Perform convolution in numpy\n",
    "def conv_numpy_2(image, weights, stride=1, pad=1):\n",
    "\n",
    "    # Perform zero padding\n",
    "    if pad != 0:\n",
    "        image = np.pad(image, ((0, 0), (0 ,0), (pad, pad), (pad, pad)),'constant')\n",
    "\n",
    "    # Get sizes of image array and kernel weights\n",
    "    batchSize,  channelsIn, imageHeightIn, imageWidthIn = image.shape\n",
    "    channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n",
    "\n",
    "    # Get size of output arrays\n",
    "    imageHeightOut = np.floor(1 + (imageHeightIn - kernelHeight) / stride).astype(int)\n",
    "    imageWidthOut = np.floor(1 + (imageWidthIn - kernelWidth) / stride).astype(int)\n",
    "\n",
    "    # Create output\n",
    "    out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype=np.float32)\n",
    "\n",
    "    for c_y in range(imageHeightOut):\n",
    "      for c_x in range(imageWidthOut):\n",
    "        for c_kernel_y in range(kernelHeight):\n",
    "          for c_kernel_x in range(kernelWidth):\n",
    "            # TODO -- Retrieve the image pixel and the weight from the convolution\n",
    "            # Only one image in batch, one input channel and one output channel, so these indices should all be zero\n",
    "            y_pos = c_y * stride + c_kernel_y\n",
    "            x_pos = c_x * stride + c_kernel_x\n",
    "              \n",
    "            # Assign correct values to this_pixel_value and this_weight\n",
    "            this_pixel_value = image[0, 0, y_pos, x_pos]\n",
    "            this_weight = weights[0, 0, c_kernel_y, c_kernel_x]\n",
    "\n",
    "            # Multiply these together and add to the output at this position\n",
    "            out[0, 0, c_y, c_x] += np.sum(this_pixel_value * this_weight)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "FeJy6Bvozgxq",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc79973e052651a91a7bd836df1f8347",
     "grade": false,
     "grade_id": "cell-b05ccf79ea5a2eb9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Results\n",
      "[[[[-0.809 -4.550 -5.486 -9.506 -4.512]\n",
      "   [-0.055  1.145 -5.388 -3.910  0.097]\n",
      "   [-0.186  0.660  1.630  2.275  4.874]\n",
      "   [ 2.386 -0.225  3.288 -4.239 -1.403]\n",
      "   [ 0.825  1.710 -3.246  3.246  1.709]\n",
      "   [ 0.809  3.695  3.491 -2.113 -2.714]]]]\n",
      "Your results\n",
      "[[[[-0.809 -4.550 -5.486 -9.506 -4.512]\n",
      "   [-0.055  1.145 -5.388 -3.910  0.097]\n",
      "   [-0.186  0.660  1.630  2.275  4.874]\n",
      "   [ 2.386 -0.225  3.288 -4.239 -1.403]\n",
      "   [ 0.825  1.710 -3.246  3.246  1.709]\n",
      "   [ 0.809  3.695  3.491 -2.113 -2.714]]]]\n"
     ]
    }
   ],
   "source": [
    "# Set random seed so we always get same answer\n",
    "np.random.seed(1)\n",
    "n_batch = 1\n",
    "image_height = 12\n",
    "image_width = 10\n",
    "channels_in = 1\n",
    "kernel_size = 3\n",
    "channels_out = 1\n",
    "stride = 2\n",
    "\n",
    "# Create random input image\n",
    "input_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))\n",
    "# Create random convolution kernel weights\n",
    "conv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))\n",
    "\n",
    "# Perform convolution using PyTorch\n",
    "conv_results_pytorch = conv_pytorch(input_image, conv_weights, stride, pad=1)\n",
    "print(\"PyTorch Results\")\n",
    "print(conv_results_pytorch)\n",
    "\n",
    "# Perform convolution in numpy\n",
    "print(\"Your results\")\n",
    "conv_results_numpy = conv_numpy_2(input_image, conv_weights, stride, pad=1)\n",
    "print(conv_results_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f0233a270fcd043746ce346e6d208b4",
     "grade": true,
     "grade_id": "cell-260f970d2ecfa687",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(conv_results_pytorch, conv_results_numpy), \"Results do not match\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3flq1Wan2gX-",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ff4a11d8077b6ed11870d071b0e7131",
     "grade": false,
     "grade_id": "cell-5e06c0f9fc8546cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we'll introduce multiple input and output channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "id": "AvdRWGiU2ppX",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1dbec87cfec006fa7001d40efc60e6a9",
     "grade": false,
     "grade_id": "cell-8846b0a94c4ab54c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Perform convolution in numpy\n",
    "def conv_numpy_3(image, weights, stride=1, pad=1):\n",
    "\n",
    "    # Perform zero padding\n",
    "    if pad != 0:\n",
    "        image = np.pad(image, ((0, 0), (0 ,0), (pad, pad), (pad, pad)),'constant')\n",
    "\n",
    "    # Get sizes of image array and kernel weights\n",
    "    batchSize,  channelsIn, imageHeightIn, imageWidthIn = image.shape\n",
    "    channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n",
    "\n",
    "    # Get size of output arrays\n",
    "    imageHeightOut = np.floor(1 + (imageHeightIn - kernelHeight) / stride).astype(int)\n",
    "    imageWidthOut = np.floor(1 + (imageWidthIn - kernelWidth) / stride).astype(int)\n",
    "\n",
    "    # Create output\n",
    "    out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype=np.float32)\n",
    "\n",
    "    for c_y in range(imageHeightOut):\n",
    "      for c_x in range(imageWidthOut):\n",
    "        for c_channel_out in range(channelsOut):\n",
    "          for c_channel_in in range(channelsIn):\n",
    "            for c_kernel_y in range(kernelHeight):\n",
    "              for c_kernel_x in range(kernelWidth):\n",
    "                  # TODO -- Retrieve the image pixel and the weight from the convolution\n",
    "                  # Only one image in batch so this index should be zero\n",
    "                  y_pos = c_y * stride + c_kernel_y\n",
    "                  x_pos = c_x * stride + c_kernel_x\n",
    "\n",
    "                  # Replace the two lines below with the correct assignments\n",
    "                  this_pixel_value = image[0, c_channel_in, y_pos, x_pos]\n",
    "                  this_weight = weights[c_channel_out, c_channel_in, c_kernel_y, c_kernel_x]\n",
    "\n",
    "                  # Multiply these together and add to the output at this position\n",
    "                  out[0, c_channel_out, c_y, c_x] += np.sum(this_pixel_value * this_weight)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "mdSmjfvY4li2",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50697705e012b5cdb83acf18221e2fc7",
     "grade": false,
     "grade_id": "cell-8b0bc6f807f622e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Results\n",
      "[[[[ -0.785   5.463  -2.480   5.026  -3.594   7.785]\n",
      "   [ -6.744   2.534  -0.664   7.149  -9.839   7.849]\n",
      "   [ -4.794  14.074  -1.060   2.706 -10.182   2.004]\n",
      "   [  1.809   0.287   4.648  -1.840   3.259   1.073]]\n",
      "\n",
      "  [[  4.150   5.372   1.699   0.500   0.589   4.361]\n",
      "   [ -4.123   5.136   4.677  -3.895  -4.990   2.546]\n",
      "   [  3.991   5.768  -2.315   8.473   1.752   2.766]\n",
      "   [  1.529   0.318  11.518  -5.444  -2.293   1.270]]]]\n",
      "Your results\n",
      "[[[[ -0.785   5.463  -2.480   5.026  -3.594   7.785]\n",
      "   [ -6.744   2.534  -0.664   7.149  -9.839   7.849]\n",
      "   [ -4.794  14.074  -1.060   2.706 -10.182   2.004]\n",
      "   [  1.809   0.287   4.648  -1.840   3.259   1.073]]\n",
      "\n",
      "  [[  4.150   5.372   1.699   0.500   0.589   4.361]\n",
      "   [ -4.123   5.136   4.677  -3.895  -4.990   2.546]\n",
      "   [  3.991   5.768  -2.315   8.473   1.752   2.766]\n",
      "   [  1.529   0.318  11.518  -5.444  -2.293   1.270]]]]\n"
     ]
    }
   ],
   "source": [
    "# Set random seed so we always get same answer\n",
    "np.random.seed(1)\n",
    "n_batch = 1\n",
    "image_height = 4\n",
    "image_width = 6\n",
    "channels_in = 5\n",
    "kernel_size = 3\n",
    "channels_out = 2\n",
    "\n",
    "# Create random input image\n",
    "input_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))\n",
    "# Create random convolution kernel weights\n",
    "conv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))\n",
    "\n",
    "# Perform convolution using PyTorch\n",
    "conv_results_pytorch = conv_pytorch(input_image, conv_weights, stride=1, pad=1)\n",
    "print(\"PyTorch Results\")\n",
    "print(conv_results_pytorch)\n",
    "\n",
    "# Perform convolution in numpy\n",
    "print(\"Your results\")\n",
    "conv_results_numpy = conv_numpy_3(input_image, conv_weights, stride=1, pad=1)\n",
    "print(conv_results_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fd3fd7d06f9739cb3ac3513e0cd0495",
     "grade": true,
     "grade_id": "cell-0c4f67b5fa61546f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(conv_results_pytorch, conv_results_numpy), \"Results do not match\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Q2MUFebdsJbH",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85bac633bf3eb6428813467d1065dc10",
     "grade": false,
     "grade_id": "cell-2cd9cc0b95bc6695",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we'll do the full convolution with multiple images (batch size > 1), and multiple input channels, multiple output channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "id": "5WePF-Y-sC1y",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e728c6d6b2b2d884ad3713a5084af6f",
     "grade": false,
     "grade_id": "cell-f5a75d4bdb9c464d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Perform convolution in numpy\n",
    "def conv_numpy_4(image, weights, stride=1, pad=1):\n",
    "\n",
    "    # Perform zero padding\n",
    "    if pad != 0:\n",
    "        image = np.pad(image, ((0, 0), (0 ,0), (pad, pad), (pad, pad)),'constant')\n",
    "\n",
    "    # Get sizes of image array and kernel weights\n",
    "    batchSize,  channelsIn, imageHeightIn, imageWidthIn = image.shape\n",
    "    channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n",
    "\n",
    "    # Get size of output arrays\n",
    "    imageHeightOut = np.floor(1 + (imageHeightIn - kernelHeight) / stride).astype(int)\n",
    "    imageWidthOut = np.floor(1 + (imageWidthIn - kernelWidth) / stride).astype(int)\n",
    "\n",
    "    # Create output\n",
    "    out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype=np.float32)\n",
    "\n",
    "    for c_batch in range(batchSize):\n",
    "      for c_y in range(imageHeightOut):\n",
    "        for c_x in range(imageWidthOut):\n",
    "          for c_channel_out in range(channelsOut):\n",
    "            for c_channel_in in range(channelsIn):\n",
    "              for c_kernel_y in range(kernelHeight):\n",
    "                for c_kernel_x in range(kernelWidth):\n",
    "                    # TODO -- Retrieve the image pixel and the weight from the convolution\n",
    "                    y_pos = c_y * stride + c_kernel_y\n",
    "                    x_pos = c_x * stride + c_kernel_x\n",
    "                    \n",
    "                    # Replace the two lines below with the correct assignments\n",
    "                    this_pixel_value = image[c_batch, c_channel_in, y_pos, x_pos]\n",
    "                    this_weight = weights[c_channel_out, c_channel_in, c_kernel_y, c_kernel_x]\n",
    "                    \n",
    "                    # Multiply these together and add to the output at this position\n",
    "                    out[c_batch, c_channel_out, c_y, c_x] += np.sum(this_pixel_value * this_weight)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1w2GEBtqAM2P",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cedf9574482673be7ad22f1edbd96d12",
     "grade": false,
     "grade_id": "cell-580d274c1df640c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Results\n",
      "[[[[ -3.633  -1.644   0.169  -1.167  -3.865   6.045]\n",
      "   [ -9.004   7.303   4.414   0.361  -6.739   3.939]\n",
      "   [ -1.391  13.502   3.807  -9.379   3.991   5.442]\n",
      "   [  2.805   6.874  -9.287  -4.468  -1.501   4.607]]\n",
      "\n",
      "  [[  1.940  -1.410   2.397  -0.235  -0.394  -1.483]\n",
      "   [  5.049  -3.335  -7.596  -1.586   3.049  -1.857]\n",
      "   [  3.514   0.475  -1.952  -1.291  -0.589  -0.948]\n",
      "   [  6.524  -0.020  -3.298  -1.248   3.249  -2.680]]]\n",
      "\n",
      "\n",
      " [[[  4.154  -4.764  11.635   0.506  -4.012  -2.081]\n",
      "   [ -1.125  -0.677  16.749  -7.030  -5.978  -2.629]\n",
      "   [  0.778  -3.984 -10.284   1.575  -8.888   1.163]\n",
      "   [  0.556  -2.290   1.407  -3.088   2.227  -5.403]]\n",
      "\n",
      "  [[  1.048   4.322  -0.901  -5.820   3.998   2.281]\n",
      "   [ -1.313   8.409  -0.100  14.625   1.223  -3.572]\n",
      "   [  1.411   1.617  -4.078  -8.107   3.705   0.229]\n",
      "   [ -3.540  -5.292  -5.619  -4.039  -4.048  -3.446]]]]\n",
      "Your results\n",
      "[[[[ -3.633  -1.644   0.169  -1.167  -3.865   6.045]\n",
      "   [ -9.004   7.303   4.414   0.361  -6.739   3.939]\n",
      "   [ -1.391  13.502   3.807  -9.379   3.991   5.442]\n",
      "   [  2.805   6.874  -9.287  -4.468  -1.501   4.607]]\n",
      "\n",
      "  [[  1.940  -1.410   2.397  -0.235  -0.394  -1.483]\n",
      "   [  5.049  -3.335  -7.596  -1.586   3.049  -1.857]\n",
      "   [  3.514   0.475  -1.952  -1.291  -0.589  -0.948]\n",
      "   [  6.524  -0.020  -3.298  -1.248   3.249  -2.680]]]\n",
      "\n",
      "\n",
      " [[[  4.154  -4.764  11.635   0.506  -4.012  -2.081]\n",
      "   [ -1.125  -0.677  16.749  -7.030  -5.978  -2.629]\n",
      "   [  0.778  -3.984 -10.284   1.575  -8.888   1.163]\n",
      "   [  0.556  -2.290   1.407  -3.088   2.227  -5.403]]\n",
      "\n",
      "  [[  1.048   4.322  -0.901  -5.820   3.998   2.281]\n",
      "   [ -1.313   8.409  -0.100  14.625   1.223  -3.572]\n",
      "   [  1.411   1.617  -4.078  -8.107   3.705   0.229]\n",
      "   [ -3.540  -5.292  -5.619  -4.039  -4.048  -3.446]]]]\n"
     ]
    }
   ],
   "source": [
    "# Set random seed so we always get same answer\n",
    "np.random.seed(1)\n",
    "n_batch = 2\n",
    "image_height = 4\n",
    "image_width = 6\n",
    "channels_in = 5\n",
    "kernel_size = 3\n",
    "channels_out = 2\n",
    "\n",
    "# Create random input image\n",
    "input_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))\n",
    "# Create random convolution kernel weights\n",
    "conv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))\n",
    "\n",
    "# Perform convolution using PyTorch\n",
    "conv_results_pytorch = conv_pytorch(input_image, conv_weights, stride=1, pad=1)\n",
    "print(\"PyTorch Results\")\n",
    "print(conv_results_pytorch)\n",
    "\n",
    "# Perform convolution in numpy\n",
    "print(\"Your results\")\n",
    "conv_results_numpy = conv_numpy_4(input_image, conv_weights, stride=1, pad=1)\n",
    "print(conv_results_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21d0bbfe4806041e354ee444c7e04cde",
     "grade": true,
     "grade_id": "cell-00ec5ea4fd9c7f7e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(conv_results_pytorch, conv_results_numpy), \"Results do not match\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNDaU2KKZDyY9Ea7vm/fNxo",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
